---
title: "Clade separation score in GUNC"
authors: "Luis Pedro Coelho"
date: 2021-02-12
---

_Initial note_: For the full story, see the [GUNC
manuscript](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02393-0).
Luis helped a bit developing the ideas behind the current iteration of the CSS
and wrote this blogpost, but most of the work was done by Askarbek, Anthony,
and Sebastian.

Let's say you have a metagenome-assembled genome (MAG) and want to check if
it's good. What should you do? Use
[checkM](https://ecogenomics.github.io/CheckM/)! Let's say you already used
CheckM and want even more assurances. In particular, you want check for
possible contamination to ensure (to the extent that it's technically feasible)
that your MAG contains only sequence from a single real genome; what can you
do?

You could use taxonomic classification of the genes in the genome. In the ideal
case, this would solve your problems directly: if all the genes are classified
as coming from the same source, then this is your genome; otherwise, you have
contamination. Unfortunately, this ideal case only works _if there are no
errors in the prediction_. In practice, taxonomic predictions are imperfect, so
what can you do?

If you have genes from two taxa (_A_ &amp; _B_) this can be because (1) your
so-called genome is actually a mixture of _A_ and _B_ or (2) the predictor is
not perfect and gets confused between the two? How can you tell? One intuition
is to look at the pattern of errors. A MAG is, effectively, a bin (_i.e._, a
group) of contigs and each contig will have a number of genes: if _A_ and _B_
are randomly spread out, then this does not provide any evidence for
contamination:

![Errors are spread: no contamination]({{ site.baseurl }}/assets/2021-02-12-GUNC/spread-out.svg)


However, if _A_ and _B_ follow contig boundaries, then this is likely
contamination:

![Errors are concentrated: contamination is likely]({{ site.baseurl }}/assets/2021-02-12-GUNC/concentrated.svg)

This assumes that most errors in MAGs are binning errors (_i.e._, the
individual contigs are good, but they are grouped incorrectly), which seems to
be empirically true.

If all you care about is getting the intuition behind a tool, you can stop
here, but now I want to show you how we went from this intuition into the
_Clade Separation Score_ implemented in the tool.

The first idea was to think in terms of _information_: how much information
about the taxonomic is provided by the contig information? This naturally lead
to the first version of our metric as a normalized form of conditional entropy:

<img src="http://latex.codecogs.com/gif.latex?\\C_1 = 1 - \frac{H(T|C)}{H(T)}" />.

Here _H(T|C)_ is the entropy of the taxonomic assignments, given the contig
assignments; which is normalized by _H(T)_ the overall taxonomic entropy. If
there is no relationship, then _H(T|C) = H(T)_, so _C₁ = 0_ (we subtract from 1
to make larger numbers denote more evidence of contatimation). On the other
hand, if the taxonomic assignments perfectly follow the contigs, then _H(T|C) =
0_ and _C₁ = 1_.

Great! So, is this what we used in the paper? **No**.

Note that this is not yet something that can be applied to data as we cannot
actually know the true value of _H(T|C)_ (or even _H(T)_, although that is less
problematic). We can estimate it from data, though. The simplest way is to use
the _plugin estimators_:

<img src="http://latex.codecogs.com/gif.latex?\\\hat{H}(T|C) = - \sum_c \sum_t \frac{a_{ct}}{N} \log \frac{a_{ct}}{N_c}" />.

In the above, _N_ is the total number of genes and <img
src="http://latex.codecogs.com/gif.latex?\\N_c" /> is the number of genes in
the contig _c_. The problem is that <em>these entropy estimators are biased and
<strong>heavily biased when <img
src="http://latex.codecogs.com/gif.latex?\\N_c" /> is generally
small</strong></em> (Basharin, 1959).

Maybe a thought experiment would illustrate the problem: imagine you have a
genome whose taxonomic assignments are exactly evenly split between two taxa
(_A_ and _B_) and without any relationship between the contig structure and the
taxonomic assignments. Imagine, however, that the genome is heavily fragmented
(_i.e._, it consists of many short contigs rather than a long
chromossome-length sequence). In this case, even though _H(T|C) = H(T)_, the
estimated versions would be biased: _Ĥ(T|C) « Ĥ(T)_. In particular, any contigs
with a single gene would be contributing zero to the sum above. Contigs with 2
genes would also show up as pure _A_ or pure _B_ contigs half the time
(randomly). Only for much larger contigs do the estimates start to be similar
to the true underlying value.

There has been some work to tackle similar issues when evaluating clustering
results (Nguyen et al., 2009; others too), but our problem is slightly
different: the fragmentation of the genome is something that we cannot do
anything about, but should not contribute any evidence of contamination.

Our first idea was to use a more robust estimator than the plugin estimator
above. This did seem to improve the results, but there was another idea that
was both conceptually very simple and easy to implement: we kept the plugin
estimator for _Ĥ(T|C)_ but also compute the same formula for a random
assignment of genes to contigs that preserves the distribution of contig sizes.
Conceptually, we perfom a permutation test: we repeatedly reassign the taxonomic
genes labels across all the genes in the genome and compute the average value
of the plugin estimator. Because of the bias discussed above, for fragmented
genomes, this value is less than _Ĥ(T)_, even though _H(T|R) = H(T)_ (if the
assignment is random, it cannot provide _any information_ about the taxonomy).
This average we call _Ĥ(T|R)_, leading to 

<div align=center>
<img src="http://latex.codecogs.com/gif.latex?\\C = 1 - \frac{\hat{H}(T|C)}{\hat{H}(T|R)}" />.
</div>

In practice, we do not need to actually perform the permutation test and can
save ourselves the computational expense of multiple randomizations to get a
mean value. In fact, another advantage of this approach is that it's very easy
to compute the closed form expression for the expected value and this is what
we use in the released version of the tool‡.

As mentioned, there is much more material in the
[manuscript](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02393-0),
including extensive validation of this concept in both simulated and real data.
All in all, we are confident that a significant fraction (~5% in isolate genome
databases, and 15-30% in MAG databases) of extant published genomes contain
some contamination and more stringent quality-control would further improve
these databases.

The tool itself can be found at [gunc.embl.de](https://gunc.embl.de/).

## References

-  Basharin GP. On a statistical estimate for the entropy of a sequence of
   independent random variables. Theory of Probability & Its Applications.
   1959;4(3):333-6. — You know you are doing real math when the papers you are
   reading have _been translated from Russian_.

- Nguyen XV, Epps J, Bailey J. Information theoretic measures for clusterings
  comparison: is a correction for chance necessary?. ICML 2009

‡ Technically, we needed to assume contigs are being sampled _with replacement_
whereas doing permutations is sampling _without replacement_, but this does not
meaningfully affect the outcome.

_History_, **June 16 2021**: this post was updated to point to the published
paper instead of the preprint.

